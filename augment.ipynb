{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c986d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torchvision.io import read_image, write_jpeg\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def load_labels(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_image(path, idx, df):\n",
    "    img_path = os.path.join(path, df.iloc[idx, 0] + '.jpg')\n",
    "    image = read_image(img_path)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def transform_image(image):\n",
    "    angle = random.randint(-180, 180)\n",
    "    image = TF.rotate(image, angle)\n",
    "    \n",
    "    hflip_prob = random.randint(1, 10)\n",
    "    if hflip_prob > 5:\n",
    "        image = TF.hflip(image)\n",
    "    \n",
    "    vflip_prob = random.randint(1, 10)\n",
    "    if vflip_prob > 5:\n",
    "        image = TF.vflip(image)\n",
    "    \n",
    "    noise_prob = random.randint(1,10)\n",
    "    if noise_prob > 5:\n",
    "        noise = torch.randint(-15, 15, size=image.size(), dtype=torch.int8)\n",
    "        # Add the noise to the image\n",
    "        image = image + noise\n",
    "        image = image.type(torch.uint8)\n",
    "\n",
    "    return image\n",
    "    \n",
    "    \n",
    "def append_df(df, labels):\n",
    "    highest_idx = len(df) - 1\n",
    "    \n",
    "    # Sanity Check\n",
    "    img_number = int(df.iloc[highest_idx]['image_name'].split('_')[1])\n",
    "    if highest_idx != img_number:\n",
    "        print(f\"[-] We got out of sync at index {highest_idx}\")\n",
    "        print(f\"{df.iloc[highest_idx]}\")\n",
    "        sys.exit(-1)\n",
    "        \n",
    "    new_idx = highest_idx + 1    \n",
    "    new_row = {\n",
    "        \"image_name\": [f\"augment_{new_idx}\"],\n",
    "        \"tags\": [' '.join(labels)]\n",
    "    }\n",
    "    return_row = {\n",
    "        \"image_name\": f\"augment_{new_idx}\",\n",
    "        \"tags\": ' '.join(labels)\n",
    "    }\n",
    "    \n",
    "    new_df = pd.concat([df, pd.DataFrame.from_dict(new_row)], ignore_index=True)\n",
    "    return new_df, return_row\n",
    "\n",
    "\n",
    "def save_image(base_path, img_name, img):\n",
    "    path = os.path.join(base_path, img_name)\n",
    "    write_jpeg(img, path, 100)\n",
    "\n",
    "    \n",
    "def get_labels(df, idx):\n",
    "    labels = df.iloc[idx]['tags']\n",
    "    return labels.strip().split(' ')\n",
    "\n",
    "\n",
    "def get_score(labels, dist, max_val):\n",
    "    label_scores = []\n",
    "    for label in labels:\n",
    "        label_scores += [ dist[label] ]\n",
    "\n",
    "    most_common = max(label_scores)\n",
    "    rarest = min(label_scores)\n",
    "    score = (1 - rarest)\n",
    "    return score, most_common\n",
    "\n",
    "\n",
    "def get_label_dist(df):\n",
    "    tags = ['haze', 'primary', 'agriculture', 'clear', 'water', 'habitation', 'road', 'cultivation', 'slash_burn',\n",
    "         'cloudy', 'partly_cloudy', 'conventional_mine', 'bare_ground', 'artisinal_mine', 'blooming',\n",
    "         'selective_logging', 'blow_down']\n",
    "    \n",
    "    dist = defaultdict(int)\n",
    "    for idx in range(len(df)):\n",
    "        labels = df.iloc[idx]['tags'].strip().split(' ')\n",
    "        for l in labels:\n",
    "            dist[l] += 1\n",
    "    \n",
    "    for t in tags:\n",
    "        dist[t] = dist[t] / len(df)\n",
    "    \n",
    "    return dist, sum(dist.values())\n",
    "\n",
    "def get_augmented_label_dist(df):\n",
    "    tags = ['haze', 'primary', 'agriculture', 'clear', 'water', 'habitation', 'road', 'cultivation', 'slash_burn',\n",
    "         'cloudy', 'partly_cloudy', 'conventional_mine', 'bare_ground', 'artisinal_mine', 'blooming',\n",
    "         'selective_logging', 'blow_down']\n",
    "    \n",
    "    dist = defaultdict(int)\n",
    "    for idx in range(len(df)):\n",
    "        if not df.iloc[idx]['image_name'].startswith('augment'):\n",
    "            continue\n",
    "        labels = df.iloc[idx]['tags'].strip().split(' ')\n",
    "        for l in labels:\n",
    "            dist[l] += 1\n",
    "    \n",
    "    for t in tags:\n",
    "        dist[t] = dist[t] / len(df)\n",
    "    \n",
    "    return dist, sum(dist.values())\n",
    "\n",
    "    \n",
    "def augment(df, base_path, new_csv='new_classes.csv'):\n",
    "\n",
    "    csv_path = os.path.join(base_path, \"train_classes.csv\")\n",
    "    img_base_path = os.path.join(base_path, \"train-jpg\")\n",
    "\n",
    "    label_dist, max_val = get_label_dist(df)\n",
    "    len_df = len(df)\n",
    "    \n",
    "    counter = 0\n",
    "    for idx in tqdm(range(10,len_df)):\n",
    "        trans_tags = df.iloc[idx]['tags'].split(' ')\n",
    "        score, score_max = get_score(trans_tags, label_dist, max_val)\n",
    "        if score < 0.9:\n",
    "            continue\n",
    "\n",
    "        if df.iloc[idx]['image_name'].startswith('augment'):\n",
    "            continue\n",
    "\n",
    "        img = load_image(img_base_path, idx, df)\n",
    "        for i in range(int(5 * score)):\n",
    "            trans_img = transform_image(img)[:3,:,:]\n",
    "            df, new_row = append_df(df, trans_tags)\n",
    "\n",
    "            save_image(img_base_path, f\"{new_row['image_name']}.jpg\", trans_img)\n",
    "            counter += 1\n",
    "\n",
    "    with open(os.path.join(base_path, new_csv), 'w') as f:\n",
    "        f.write(df.to_csv(index=False))\n",
    "    \n",
    "    print(f\"Augmented {counter} images\")\n",
    "\n",
    "    df_new = load_labels(os.path.join(base_path, new_csv))\n",
    "    label_dist_new, _ = get_label_dist(df_new)\n",
    "\n",
    "    augmented_label_dist, _ = get_augmented_label_dist(df_new)    \n",
    "    return df_new, label_dist_new, augmented_label_dist\n",
    "\n",
    "\n",
    "def normalize_labels(df, label_dist, threshold=500):\n",
    "    tmp_dist = label_dist.copy()\n",
    "    new_df = pd.DataFrame(columns=['image_name', 'tags'])\n",
    "    label_count = defaultdict(int)\n",
    "    t = tqdm(total=len(label_dist), position=0, leave=True)\n",
    "    \n",
    "    while tmp_dist:\n",
    "        t.update(1)\n",
    "        rarest_label = min(tmp_dist, key=tmp_dist.get)\n",
    "        \n",
    "        if label_count[rarest_label] >= threshold:\n",
    "            tmp_dist.pop(rarest_label)\n",
    "            continue\n",
    "        \n",
    "        for idx in range(len(df)):\n",
    "            tags = df.loc[idx, \"tags\"].split(' ')\n",
    "            \n",
    "            if rarest_label in tags:\n",
    "                new_df = pd.concat([new_df, df.iloc[idx].to_frame().T], ignore_index=True, axis=0)\n",
    "                \n",
    "                for local_tag in tags:\n",
    "                    label_count[local_tag] += 1\n",
    "            \n",
    "            if label_count[rarest_label] >= threshold:\n",
    "                break\n",
    "        \n",
    "        tmp_dist.pop(rarest_label)\n",
    "\n",
    "    t.close()\n",
    "    return new_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e870fe1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 17/17 [00:06<00:00,  2.55it/s]\n"
     ]
    }
   ],
   "source": [
    "base_path = '/path/where/the/train/images/folder/lies'\n",
    "csv_path = os.path.join(base_path, \"train_classes.csv\")\n",
    "delete_csv = os.path.join(base_path, \"delete_classes.csv\")\n",
    "\n",
    "df_orig = load_labels(csv_path)\n",
    "dist_orig, _ = get_label_dist(df_orig)\n",
    "\n",
    "df_augment, dist_new, dist_augment_only = augment(df_orig, base_path, 'new_classes.csv')\n",
    "df_delete = normalize_labels(df_augment, dist_augment, 500)\n",
    "\n",
    "delete_dist, _ = get_label_dist(df_delete)\n",
    "with open(delete_csv, 'w') as f:\n",
    "    f.write(df_delete.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1daf1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
