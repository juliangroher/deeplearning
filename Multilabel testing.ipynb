{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import sys\n",
    "\n",
    "# Function handle that returns an optimizer\n",
    "def get_optimizer(model, name='adam', lr=0.001, momentum=0.9):\n",
    "    if name == 'adam':\n",
    "        return optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    elif name == 'sgd':\n",
    "        return optim.SGD(model.parameters(), lr=lr,momentum=momentum)\n",
    "    else:\n",
    "        print(f'[-] Unknown optimizer {name}')\n",
    "        sys.exit(-1)\n",
    "\n",
    "# Function handle that updates the learning rate\n",
    "# (note this is a dummy implementation that does nothing)\n",
    "def get_lrs(optimizer, name='ReduceLROnPlateau'):\n",
    "    if name == \"ReduceLROnPlateau\":\n",
    "        return optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5)\n",
    "\n",
    "    elif name == \"StepLR\":\n",
    "        return optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    elif name == 'MultiStepLR':\n",
    "        return optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,30], gamma=0.1)\n",
    "\n",
    "    else:\n",
    "        print(f\"[-] Unknown scheduler {name}\")\n",
    "        sys.exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "a5611eb171a04fefa796d84ec23f942e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 43,
    "execution_start": 1669369921652,
    "source_hash": "c7512eea",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights, resnet\n",
    "from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights, mobilenetv3\n",
    "\n",
    "# Global Variables\n",
    "local = True\n",
    "data_path = 'datasets/deeplearningproject/'\n",
    "if not local:\n",
    "    data_path = os.path.join('/', data_path)\n",
    "images_path = os.path.join(data_path, 'train-jpg')\n",
    "label_path = os.path.join(data_path, 'train_classes.csv')\n",
    "\n",
    "\n",
    "# network_weights = MobileNet_V3_Small_Weights.DEFAULT\n",
    "# encoder = mobilenet_v3_small(weights=network_weights)\n",
    "network_weights = ResNet50_Weights.DEFAULT\n",
    "encoder = resnet50(weights=network_weights)\n",
    "preprocess = network_weights.transforms()\n",
    "\n",
    "\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer_name = 'adam'\n",
    "lrs_name = 'StepLR'\n",
    "\n",
    "\n",
    "batch_size = 40\n",
    "epochs = 20\n",
    "workers = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "5650ec94cb1f4897afd6da801a4d5b2e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1669369930616,
    "source_hash": "88c39b50",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reset_parameters(net):\n",
    "    '''Init layer parameters.'''\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            torch.nn.init.kaiming_normal_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                torch.nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            torch.nn.init.constant_(m.weight, 1) # Why 1?\n",
    "            torch.nn.init.constant_(m.bias, 0) # Why 0?\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            torch.nn.init.kaiming_normal_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "#reset_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "4b7aed3c4e484fdeac033de70b9bfb62",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 295,
    "execution_start": 1669369930624,
    "source_hash": "110abd7e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def Net():\n",
    "    for param in encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    if isinstance(encoder, mobilenetv3.MobileNetV3):\n",
    "        decoder = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=576,out_features=120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=120, out_features=17),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        for param in decoder.parameters():\n",
    "            param.requires_grad=True\n",
    "\n",
    "        encoder.classifier = decoder\n",
    "    elif isinstance(encoder, resnet.ResNet):\n",
    "        decoder = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=2048,out_features=120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=120, out_features=17),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        for param in decoder.parameters():\n",
    "            param.requires_grad=True\n",
    "\n",
    "        encoder.fc = decoder\n",
    "    else:\n",
    "        print(f\"[-] Unknown encoder Model: {type(encoder)}\")\n",
    "\n",
    "    return encoder\n",
    "\n",
    "model = Net()\n",
    "\n",
    "# print('Network parameters:\\n')\n",
    "# print(model)\n",
    "\n",
    "# Print parameter shapes\n",
    "# for name, param in model.named_parameters(): print('parameter',name,param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "11de6fe699974f1ba8fdd3a7ca04db41",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1669369930807,
    "source_hash": "81cc7f59",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#weights = ResNet50_Weights.DEFAULT\n",
    "#preprocess = weights.transforms()\n",
    "#\n",
    "#img = images[0]\n",
    "#print(img.shape)\n",
    "#img_transformed = preprocess(img)\n",
    "#print(img_transformed.shape)\n",
    "#\n",
    "#scores = model(images)\n",
    "#print(scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "dd806cf511d246789cdd69ade5f973ff",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1669369930808,
    "source_hash": "ee94e884",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(scores, yb):\n",
    "    # print(\"scores\", scores.dtype)\n",
    "    # print(\"yb\", yb.dtype)\n",
    "    # Binarize predictions via thresholding\n",
    "    scores[scores>=0.5] = 1\n",
    "\n",
    "    return (scores == yb).float().mean()\n",
    "\n",
    "#print('Accuracy', accuracy(scores,labels))\n",
    "\n",
    "# loss_func = F.cross_entropy\n",
    "\n",
    "#loss = loss_func(scores, labels)\n",
    "#print('Loss', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "8104e336c8fb4cf5b6986a6a564b6182",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 546,
    "execution_start": 1669369930813,
    "source_hash": "a75c275e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from time import process_time\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "class MultilabelDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None, target_transform=None, preprocessor=None):\n",
    "        self.img_dataframe = dataframe  # pd.read_csv(annotation_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "        # Encode labels\n",
    "        tags = ['haze', 'primary', 'agriculture', 'clear', 'water', 'habitation', 'road', 'cultivation', 'slash_burn',\n",
    "         'cloudy', 'partly_cloudy', 'conventional_mine', 'bare_ground', 'artisinal_mine', 'blooming',\n",
    "         'selective_logging', 'blow_down']\n",
    "        split_tags = [row.split(\" \") for row in self.img_dataframe[\"tags\"]]\n",
    "        mlb = MultiLabelBinarizer(classes=tags)\n",
    "        mlb.fit(split_tags)\n",
    "        self.img_labels = mlb.transform(split_tags).astype('float32')  # BCELoss does not accept integers *for some reason*\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(idx)\n",
    "        # print(self.img_dataframe[idx-10:idx+10])\n",
    "        img_path = os.path.join(self.img_dir, self.img_dataframe.iloc[idx, 0] + '.jpg')\n",
    "        # print(img_path)\n",
    "        pre_time = process_time()\n",
    "        image = read_image(img_path)\n",
    "        image = image [:3,:,:] #remove alpha channel\n",
    "        loaded_time = process_time()\n",
    "\n",
    "        if self.preprocessor != None:\n",
    "            image = image/255 #required for preprocessor | normalize each picture\n",
    "            image = self.preprocessor(image)\n",
    "        else:\n",
    "            image = 2 * (image/255 - 0.5) #normalize each picture\n",
    "\n",
    "        processed_time = process_time()\n",
    "        labels = self.img_labels[idx]\n",
    "\n",
    "        transform_time = process_time()\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            labels = self.target_transform(labels)\n",
    "\n",
    "        post_time = process_time()\n",
    "\n",
    "        # print(\"load\", loaded_time - pre_time, \"processing\", processed_time - loaded_time, \"labels\", transform_time - processed_time, \"transform\", post_time - transform_time)\n",
    "        # print(\"total\", post_time - pre_time)\n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "d75acf46db9a4f4ea2236e4861042197",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 88,
    "execution_start": 1669369931363,
    "source_hash": "55d7171b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "labels = pd.read_csv(label_path)\n",
    "train_data, test_daa = train_test_split(labels[:500], train_size=0.9)\n",
    "\n",
    "trainset = MultilabelDataset(\n",
    "    train_data,\n",
    "    images_path,\n",
    "    preprocessor=preprocess\n",
    ")\n",
    "\n",
    "testset = MultilabelDataset(\n",
    "    test_daa,\n",
    "    images_path,\n",
    "    preprocessor=preprocess\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "35b72d6e673b46d9b43bea464f20c86a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 550,
    "execution_start": 1669369931496,
    "source_hash": "79f5ed44",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to fit a model\n",
    "def fit(model,\n",
    "        opt,\n",
    "        lr_scheduler,\n",
    "        loss_func,\n",
    "        bs=256,\n",
    "        epochs=1,\n",
    "        batches_per_epoch=None, # Default: Use entire training set\n",
    "        show_summary=True,\n",
    "        workers=0):\n",
    "\n",
    "  # Set up data loaders\n",
    "  if batches_per_epoch == None:\n",
    "    # Use all images\n",
    "    train_dl = torch.utils.data.DataLoader(trainset, batch_size=bs,\n",
    "                                          shuffle=True, num_workers=workers, persistent_workers=workers)\n",
    "    valid_dl = torch.utils.data.DataLoader(testset, batch_size=bs,\n",
    "                                         shuffle=False, num_workers=workers, persistent_workers=workers)\n",
    "    batches_per_epoch = len(train_dl)\n",
    "  else:\n",
    "    # Only use a subset of the data\n",
    "    subset_indices = list(range(batches_per_epoch*bs))\n",
    "    train_dl = torch.utils.data.DataLoader(trainset, batch_size=bs, sampler=torch.utils.data.sampler.SubsetRandomSampler(subset_indices), num_workers=workers, persistent_workers=workers)\n",
    "\n",
    "    # Use one fourth for validation\n",
    "    subset_indices = list(range(int(np.ceil(batches_per_epoch/4))*bs))\n",
    "    valid_dl = torch.utils.data.DataLoader(testset, batch_size=bs, sampler=torch.utils.data.sampler.SubsetRandomSampler(subset_indices), num_workers=workers, persistent_workers=workers)\n",
    "\n",
    "  # For book keeping\n",
    "  train_loss_history = []\n",
    "  valid_loss_history = []\n",
    "  plot_time_train = []\n",
    "  plot_time_valid = []\n",
    "\n",
    "  # Index of current batch\n",
    "  t = 1\n",
    "\n",
    "  # Total number of batches\n",
    "  T = batches_per_epoch * epochs\n",
    "  \n",
    "  print('Epochs:',epochs,'Batches per epoch:',batches_per_epoch,'Total number of batches',T)\n",
    "  \n",
    "  # Get initial validation loss and accuracy\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    if torch.cuda.is_available():\n",
    "        valid_acc = sum(accuracy(model(xb.cuda()), yb.cuda()) for xb, yb in valid_dl) / len(valid_dl)\n",
    "        valid_loss = sum(loss_func(model(xb.cuda()), yb.cuda()) for xb, yb in valid_dl) / len(valid_dl)\n",
    "        valid_loss_history.append(valid_loss.detach().cpu().numpy())\n",
    "        plot_time_valid.append(t)\n",
    "    else:\n",
    "        valid_acc = sum(accuracy(model(xb), yb) for xb, yb in valid_dl) / len(valid_dl)\n",
    "        valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl) / len(valid_dl)\n",
    "        valid_loss_history.append(valid_loss.detach().cpu().numpy())\n",
    "        plot_time_valid.append(t)\n",
    "\n",
    "  # Train\n",
    "  for epoch in range(epochs):\n",
    "    model.train() # Train mode    \n",
    "\n",
    "    for xb, yb in train_dl:\n",
    "\n",
    "      # Forward prop      \n",
    "      if torch.cuda.is_available():\n",
    "        pred = model(xb.cuda())\n",
    "        loss = loss_func(pred, yb.cuda())\n",
    "      else:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb) \n",
    "\n",
    "      # Book keeping\n",
    "      train_loss_history.append(loss.detach().cpu().numpy())\n",
    "      plot_time_train.append(t)\n",
    "      t += 1\n",
    "\n",
    "      # Backward prop (calculate gradient)\n",
    "      loss.backward()\n",
    "      \n",
    "      # Update model parameters\n",
    "      opt.step()\n",
    "      opt.zero_grad()\n",
    "\n",
    "\n",
    "      # Validation loss and accuracy\n",
    "      if t % 10 == 0:\n",
    "        model.eval() # Test mode\n",
    "        with torch.no_grad():\n",
    "            if torch.cuda.is_available():\n",
    "                valid_acc = sum(accuracy(model(xb.cuda()), yb.cuda()) for xb, yb in valid_dl) / len(valid_dl)\n",
    "                valid_loss = sum(loss_func(model(xb.cuda()), yb.cuda()) for xb, yb in valid_dl) / len(valid_dl)\n",
    "            else:\n",
    "                valid_acc = sum(accuracy(model(xb), yb) for xb, yb in valid_dl) / len(valid_dl)\n",
    "                valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl) / len(valid_dl)\n",
    "        \n",
    "            valid_loss_history.append(valid_loss.detach().cpu().numpy())\n",
    "            plot_time_valid.append(t-1)\n",
    "            print('t',t,'lr',opt.param_groups[0]['lr'],'train loss',loss.detach().cpu().numpy(), 'val loss',valid_loss.detach().cpu().numpy(),'val accuracy', valid_acc.detach().cpu().numpy())\n",
    "        \n",
    "        model.train() # Back to train mode\n",
    "    \n",
    "    # Update learning rate once per epoch \n",
    "    lr_scheduler.step()\n",
    "\n",
    "  # Summary\n",
    "  if show_summary:\n",
    "    plt.figure()\n",
    "    lines = []\n",
    "    labels = []\n",
    "    l, = plt.plot(plot_time_train,train_loss_history)\n",
    "    lines.append(l)\n",
    "    labels.append('Training')\n",
    "    l, = plt.plot(plot_time_valid,valid_loss_history)\n",
    "    lines.append(l)\n",
    "    labels.append('Validation')  \n",
    "    plt.title('Loss')\n",
    "    plt.legend(lines, labels, loc=(1, 0), prop=dict(size=14))\n",
    "    plt.show()\n",
    "\n",
    "  return train_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e723d1abe048472ea80265bdb44d80a0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 96926,
    "execution_start": 1669369932046,
    "source_hash": "14d2e592",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 20 Batches per epoch: 12 Total number of batches 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gro/Documents/Uni/Erasmus/Vorlesungen/DLVR/Project/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t 10 lr 0.001 train loss 0.31223255 val loss 0.46332943 val accuracy 0.09926471\n"
     ]
    }
   ],
   "source": [
    " # Re-initialize weights\n",
    "#reset_parameters(model)\n",
    "model = Net()\n",
    "\n",
    "optimizer = get_optimizer(model, optimizer_name)\n",
    "lrs = get_lrs(optimizer, lrs_name)\n",
    "\n",
    "# Train with defaul settings.\n",
    "train_loss_history = fit(model, loss_func=loss_function,\\\n",
    "                         opt=optimizer, lr_scheduler=lrs, bs=batch_size, epochs=epochs, workers=workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=523d2edd-b418-4a9e-989b-f9b1860f5009' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "2569b25dc7904ddf9bcdb5798f2407eb",
  "deepnote_persisted_session": {
   "createdAt": "2022-11-09T15:15:44.543Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
